---
title: "Mathematical Methods for Political Analysis"
author: "Ian Myers"
date: "5/7/2020"
output:
  github_document:
    pandoc_args: --webtex
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(reshape2)
library(nFactors)
library(lavaan)
library(semPlot)
library(dplyr)
library(stargazer)
library(ggplot2)
library(psych)
library(kableExtra)
library(GPArotation)
```

```{r Data Prep, echo=FALSE}
load("data/MMdata_merged.rdata")
data <- MMdata_merged

#Remove Observations that Refused to Answer

data <- subset(data, C1 > 0 & C2 > 0 & C3 > 0 &
                 
                     I1 > 0 & I3 > 0 & I4 > 0 & 
                     I7 > 0 & 
                 
                     MR2 > 0 & MR3 > 0 & 
                     
                     L1 > 0 & L2 > 0 & L3 > 0 &
                     L4 > 0 & L5 > 0 & L6 > 0 &
                     L7 > 0 & L8 > 0 & L9 > 0 & 
                     L10 > 0 & L11 > 0 & L12 > 0 & 
                     L13 > 0 & L14 > 0 & L15 > 0 &
                     L16 > 0 & 
                 
                     DPES13 > 0 & DPES14 > 0 & DPES15 > 0 & 
                     DPES19 >0 & 
                 
                     DIT0 > 0 & DIT1 > 0 & DIT2 >0 &
                     DIT5 > 0 & DIT6 > 0 & DIT7 > 0 & 
                     DIT8 > 0 & DIT9 > 0 & DIT10 >0 &
                     DIT11 > 0 & DIT12 > 0 & 
                 
                     MELS1 > 0 & MELS2 > 0 & MELS3 > 0 &
                     MELS4 > 0 & MELS5 > 0 & MELS6 > 0 &
                     MELS7 > 0 & MELS8 > 0 & MELS9 > 0 &
                     MELS10 > 0 & MELS11 > 0 & MELS12 > 0 &
                     
                     MFSS1 > 0 & MFSS2 > 0 & MFSS3 > 0 &
                     MFSS4 > 0 & MFSS5 > 0 & MFSS6 > 0 &
                     MFSS7 > 0 & MFSS8 > 0 & MFSS9 > 0 &
                     MFSS10 > 0 & MFSS11 > 0 & MFSS12 > 0 &
                     MFSS16 > 0 & MFSS17 > 0 & MFSS18 > 0 &
                 
                     SV1 > 0 & SV3 > 0 & SV7 > 0 &
                     SV11 > 0 & SV12 > 0 & SV16 > 0 &
                     SV17 > 0 & SV18 > 0 & SV20 > 0 &
                 
                     EVA2 > 0 & EVA4 > 0 & EVA5 > 0 &
                     EVA6 > 0 & EVA7 > 0 & EVA8 > 0 &
                     EVA9 > 0 & EVA11 > 0 & EVA12 > 0 
               )

                 
```

# Testing the Limits of Moral Foundations Theory

## Introduction

In "Mapping the Moral Domain," Graham et al. find that moral judgments can be grouped into five categories, or "moral foundations": care, fairness, loyalty, (respect for) authority, and purity. On the basis of moral foundations theory, the authors predict that humans vary in the moral judgments not just by being more or less moral, and not just by being more or less concerned with individuals and more or less concerned with community, but by being more or less concerned with each of five different qualities that can be morally relevant. One of the payouts of this theory is the possibility that two people, despite neither one being more "moral" than the other, can have radically different judgments not only about what is right and what is wrong but also about what is and is not a moral question at all. Now, in its most consistent form, this theory seems to me to be a theory about the form of morality, as distinguished from the content of morality. That is, it does seem to me to claim that those equally concerned with purity, for example, will agree about all or even most questions of moral purity--they might disagree on what is pure and what is impure. It seems to claim rather that we can think of moral judgments and beliefs as originating from five distinct "cognitive modules" or ways of thinking about what is moral. Two people who disagree about what constitutes purity and impurity nevertheless, according to this theory, are importantly akin to each other, for whereas others might not place moral weight on purity, these two do. To test this theory, the authors devised a 30 item survey composed of five groups that each contain six items designed to reveal the saliency of one of the moral foundations to the respondent. After collecting more than 34,000 responses to this survey using a publicly accessible website, the authors performed confirmatory factor analysis with several models, one of which was the five-factor model predicted by moral foundations theory. They found that the five-factor model fit the data better than the other tested models and was a good fit by the standard of conventional measures of goodness of fit for factor models. 

In this short paper, I attempt to replicate, in a loose sense of the term, Graham et al.'s findings. More precisely, I am interested here in seeing whether the predictions of moral foundations theory find confirmation using data from surveys that, one one hand, were not specially designed by Graham et al. but, on the other, contain items that can be intuitively grouped in accordance with the five proposed moral foundations (proper replications of Graham et al.'s results have been done. See eg. Davies 2014, Tamul 2020, and Yilmaz 2016). If the predictions can find confirmation in this way, then the possibility that the significance of the five foundations is contingent on the specific items chosen in Graham et al.'s survey, which would mean that the five foundations are not useful for understanding moral judgments as they occur in the complexity of everyday life, will be diminished. First, I compare the fit of the moral foundations model to data generated from a second survey designed by some of the authors of "Mapping the Moral Domain" to the fit of alternative models. Then, I do the same with data generated from a collection of items I took from distinct questionnaires that were all answered by respondents in one survey. Finally, on account of the problems with the previous approach, I test the moral foundations model on data generated from a questionnaire designed to measure the moralization of everyday life situations. I find that 1) the moral foundations model does reasonably well compared to other models in all three cases and 2) the moral foundations model does not reach the level of goodness of fit Graham et al. found it to reach in their article.

\newpage

## Testing Moral Foundations on Friendly Scales

This part of the project is the closest to a proper replication of Graham et al.'s results. Here I do confirmatory factor analysis on data generated by a questionnaire designed for the purpose of measuring a respondent's moral foundations score by researchers who collaborated in Graham et al.'s paper (Graham & Haidt 2012). If Graham et al.'s results are robust, then a five-factor model that admits of correlation between the factors should fit the data generated by this questionnaire well. 

The Measuring Morality project, directed by Stephen Vaisey, collected nationally representative survey data from 1519 participating adults. The Measuring Morality survey combines 19 morality scales and measures of other constructs that may be associated with morality. One of these 19 scales is the Moral Foundations Sacredness Scale (MFSS), which measures the sacredness respondents assign to each of the five moral foundations. The MFSS is divisible into six sets of three questions (Graham & Haidt 2012). Each set of questions corresponds either to one of the five moral foundations or to non-moral judgments. Each question asks how much money the respondent would have to be offered in order to do a specific action, with the stipulation that the actions will have no lasting negative consequences for the respondent. The questions are thus meant to force the respondent to abstract from prudential considerations and judge the merits of the action by reference to itself alone. If the respondents follow these instructions properly, then the amount of money required by the participant to do the action should correspond to the sacredness they assign to the moral principle the action violates. Respondents have eight response options ranging from "\$0 (I'd do it for free)" on the low end to "\$1 million dollars or more [sic]" and then "never for any amount of money" on the high end. Responses between \$0 and \$1 million increase by factors of 10. Below are examples of actions asked about in the items of each of the groups, along with their corresponding moral foundations.

### Care

Stick a pin in the palm of a child you don't know

### Fairness

Throw out a box of ballots, during an election, to help your favored candidate win

### Authority

Make a disrespectful hand gesture to your boss, teacher, or professor

### Loyalty

Burn your country's flag, in private

### Purity

Get a blood transfusion of one pint of disease-free, compatible blood from a convicted child molester

### Non-Moral

"Sit in a bathtub of ice water for 10 minutes"

Again, since the questionnaire is designed to discriminate between the five moral foundations (in addition to the non-moral), we expect that a five-factor model, in which each factor is tied to the items relevant to each foundation, should fit the data better than a model with fewer factors and better than theoretically plausible alternatives. To test this, I create  seven models and compare their fits. Each model ignores the non-moral questions and concerns only the moral items since Graham et al.'s paper does not deal with non-moral survey items and does not lay out a theoretical framework for understanding the relation between non-moral questions such as these and questions that represent the moral foundations. The fit comparisons of models of this sort are thus more relevant to the replication of Graham et al.'s results. I include a simple one-factor model, a two-factor model that ties care and fairness together in one factor and authority, loyalty, and purity together in another factor, a three-factor model that is the same as the previous except in giving purity its own factor, a four-factor model that gives every foundation its own factor except for authority and loyalty, a five-factor model that gives every foundation its own factor, and, finally, a second two-factor model and a second five-factor model the details of which will be given below. The first four models are taken from Graham et al.'s paper. The theoretical intuitions for these four models are as follows:

### One-factor Model 

Moral judgments and beliefs are dependent on a single unobserved variable, namely a person's morality, and any variations among what people with similar levels of morality think is moral or immoral are random.

### Two-Factor Model 

Someone's concern for the well-being of others (care) and fairness is independent or relatively independent from their concern with social hierarchies (authority), their group (loyalty), and bodily and spiritual purity. We should expect this because concerns for care and fairness are both concerns for the treatment of individuals whereas concerns for authority, loyalty, and purity are concerns for the integrity of one's group.

### Three-Factor Model

The thought behind this model is the same as that behind the two-factor model, with the difference that here the observation that purity is only ambiguously tied to group integrity, on one hand, and often irrelevant to the treatment of others (acts that are immoral on account of being impure need not harm anyone other than the one committing them), on the other, is taken to suggest that purity is independent or relatively independent from the previous two groups of concerns. 

### Four-Factor Model

The thought here is the same as the above except that the observations that fairness and care often conflict (example: someone might steal another's gun when the other appears to be out of his mind) is taken to suggest that concerns for fairness and care are independent or relatively independent from each other.

The sixth model is suggested by exploratory factor analysis of the data. The scree plot for the data without the non-moral items is shown below. Although eyeballing the plot would suggest using only one factor, we already have a one-factor model, and several of the significance metrics included in the upper-right corner of the plot indicate two factors should be used. The results of EFA with two factors, which are shown below in Table 1, do not, suggest an intelligible grouping of the items. The second factor loads highly onto two of the fairness items and all the care items, which would be expected given the hypothesis that care and fairness are foundations connected in being concerned with the treatment of individuals. Moreover, the inclusion of the first authority item and the second loyalty item could be explained by the fact that those two items both concern one's treatment of one's family. One might suppose that the two family-related items are inadvertently measuring concern for the well-being of one's loved ones or that they are measuring a specific type of loyalty, familial loyalty, and that familial loyalty, in distinction from other types of loyalty, flies together with care and fairness. I cannot, however, see a plausible explanation of the first fairness item having higher loadings under the first factor than the second, and for that reason, the model I will test when doing confirmatory analysis will include the first fairness item along with the other fairness items in the second factor. I will discuss the dangers of this sort of post hoc hypothesizing below. I am now engaging in it only for the sake of curiosity.

The seventh model is suggested by EFA using five factors. Using five factors is not warranted by the scree plot and the eigenvalue significance metrics included in its upper-right corner, so I am doing this only for curiosity's sake. That curiosity is rewarded--the results of the five-factor exploration, listed below in Table 2 (all EFA done in this paper used MLE estimation and direct oblimin rotation, following Graham et al. 2011), are quite interesting and suggest a grouping of the survey items made on the basis not of moral foundations but of human types or characters, which overlap the moral foundations. To help indicate what I mean by this, I will list the actions asked about in each item under the factor that loaded most highly onto them.

```{r Scree plot for MFSS, fig.width=5, fig.height=4, fig.cap="MFSS Scree Plot",fig.align = "center", echo=FALSE}

#Creating Dataframe

MFSSData <- as.data.frame(data[,160:177])

names(MFSSData)[1] <- "F1"
names(MFSSData)[2] <- "F2"
names(MFSSData)[3] <- "F3"
names(MFSSData)[4] <- "L1"
names(MFSSData)[5] <- "L2"
names(MFSSData)[6] <- "L3"
names(MFSSData)[7] <- "A1"
names(MFSSData)[8] <- "A2"
names(MFSSData)[9] <- "A3"
names(MFSSData)[10] <- "P1"
names(MFSSData)[11] <- "P2"
names(MFSSData)[12] <- "P3"
names(MFSSData)[13] <- "N1"
names(MFSSData)[14] <- "N2"
names(MFSSData)[15] <- "N3"
names(MFSSData)[16] <- "C1"
names(MFSSData)[17] <- "C2"
names(MFSSData)[18] <- "C3"

#Scree plot

eigen <- eigen(cor(MFSSData[,c(1:12,16:18)]))

ap <- parallel(subject=nrow(MFSSData[,c(1:12,16:18)]),var=ncol(MFSSData[,c(1:12,16:18)]),
  rep=100,cent=.05)

nS <- nScree(x=eigen$values, aparallel=ap$eigen$qevpea)
plotnScree(nS)
```

```{r, EFA for MFSS, echo=FALSE}
#EFA

solution <- kaiser(fa(r = MFSSData[,c(1:12,16:18)], nfactors = 2, rotate = "oblimin", fm = "mle"))
kable_styling(kable(round(loadings(solution), 2), caption='Two Factors'))

solution <- kaiser(fa(r = MFSSData[,c(1:12,16:18)], nfactors = 5, rotate = "oblimin", fm = "mle"))
kable_styling(kable(round(loadings(solution), 2), caption='Five Factors'))

```


### Factor 1

F1: Cheat in a game of cards played for money with some people you don't know well
F2: Throw out a box of ballots, during an election, to help you favored candidate win
F3: Sign a secret but binding pledge to only hire people of your race in your company

### Factor 2

L1: Say something bad about your nation (which you don't believe to be true) while calling
in, anonymously, to a talk-radio show in a foreign nation
L3: Burn your country’s flag, in private (nobody else sees you)
P1: Sign a piece of paper that says 'I hereby sell my soul, after my death, to whoever has
this piece of paper'

### Factor 3

A2: Make a disrespectful hand gesture to your boss, teacher, or professor
A3: Throw a rotten tomato at a political leader you dislike
P2: Get a blood transfusion of one pint of disease-free, compatible blood from a convicted
child molester
C2: Make cruel remarks to an overweight person about his or her appearance

### Factor 4

L2: Break off all communications with your immediate and extended family for 1 year
-L3: Burn your country’s flag, in private (nobody else sees you)
A1: Curse your parents, to their face. (You can apologize and explain one year later)
P1: Sign a piece of paper that says 'I hereby sell my soul, after my death, to whoever has
this piece of paper'

### Factor 5

C1: Kick a dog in the head, hard
C3: Stick a pin into the palm of a child you don’t know

Factor 1 loads highly onto the three fairness items, indicating that concern for fairness is a relatively unified and independent quality. Factor 2, however, does not load highly onto just one set of items. It seems rather to be a combination of patriotism (loyalty particular to one's country, as opposed, for example, to one's family) and religious or spiritual concern. Interestingly, Factor 4 appears to be a counterpart to Factor 2: the combination of loyalty to one's family (and not so much one's country--this factor has a negative loading on burning the flag) with religious or spiritual concern. If factor 2 is pious patriotism, factor 4 is familial piety. Factor 5 is obviously that part of care that concerns physical harm. Interestingly, factor 3 loads more heavily on the care item that concerns verbal and emotional harm, suggesting that the care foundation is actually divided between physical and verbal or emotional harm. Moreover, factor 3 appears to represent a concern for politeness that encompasses parts of the authority and care foundations. I must, however, admit that I cannot account for why factor 3 might load highly onto the purity item concerning blood transfusions. With that being said, however, these results from EFA with five factors paint a fairly plausible alternate picture of the moral foundations. They suggest that the moral foundations of Graham et al.'s research are actually divided up among what I am tempted to call human moral types that consist of clusters of different, and perhaps a priori independent, moral beliefs and concerns.

Moving onto confirmatory factor analysis, I have listed the first set of models, along with their fit statistics, in the figures below and Table 3 above.


```{r CFA for MFSS, include=FALSE}

#Single Factor

MFSSModelOne <- 'All =~ C1+ C2 + C3 + F1+ F2 + F3 + A1+ A2 + A3 + L1+ L2 + L3 + P1+ P2 + P3' 
OneFac <- cfa(MFSSModelOne, data=MFSSData,std.lv=TRUE) 


#Two Factors

MFSSModelTwoAlt <- 'Care.Fairness.Modified =~ C1+ C2 + C3 + F1+ F2 + F3 + A1 + L2
                Authority.Loyalty.Purity.Modified =~ A2 + A3 + L1 + L3 + P1+ P2 + P3' 
TwoFacAlternative <- cfa(MFSSModelTwoAlt, data=MFSSData,std.lv=TRUE) 


#Two Factors Alt

MFSSModelTwo <- 'Care.Fairness =~ C1+ C2 + C3 + F1+ F2 + F3 
                Authority.Loyalty.Purity =~ A1+ A2 + A3 + L1+ L2 + L3 + P1+ P2 + P3' 
TwoFac <- cfa(MFSSModelTwo, data=MFSSData,std.lv=TRUE) 


#Three Factors

MFSSModelThree <- 'Care.Fairness =~ C1+ C2 + C3 + F1+ F2 + F3
                  Authority.Loyalty =~ A1+ A2 + A3 + L1+ L2 + L3
                  Purity =~ P1+ P2 + P3' 
ThreeFac <- cfa(MFSSModelThree, data=MFSSData,std.lv=TRUE) 


#Four Factors

MFSSModelFour <- 'Care =~ C1+ C2 + C3 
                  Fairness =~ F1+ F2 + F3
                  Authority.Loyalty =~ A1+ A2 + A3 + L1+ L2 + L3
                  Purity =~ P1+ P2 + P3' 
FourFac <- cfa(MFSSModelFour, data=MFSSData,std.lv=TRUE) 


#Five Factors MF

MFSSModelFiveMF <- 'Care =~ C1+ C2 + C3
                 Fairness =~ F1+ F2 + F3
                 Authority =~ A1+ A2 + A3
                 Loyalty =~ L1+ L2 + L3
                 Purity =~ P1+ P2 + P3' 
FiveFacMF <- cfa(MFSSModelFiveMF, data=MFSSData,std.lv=TRUE) 


#Five Factors Alt

MFSSModelFiveAlt <- 'Physical Care =~ C1 + C3
                 Fairness =~ F1+ F2 + F3
                 Politeness =~ A2 + A3 + C2
                 Familial =~ L2 + L3 + A1 + P1
                 Patriotism =~ L1 + L3 + P1' 
FiveFacAlternative <- cfa(MFSSModelFiveAlt, data=MFSSData,std.lv=TRUE) 


```


```{r MFSS Fit Statistics, fig.asp=.3, fig.cap="Models", echo=FALSE}
#Fit Statistics 

fitable <- function(model){ # take a lavaan model, output nice tables with the models fit measures
    require(dplyr)
    measures <- fitMeasures(model,
    c("chisq","df","cfi",
      "rmsea", "rmsea.ci.lower", "rmsea.ci.upper")) %>%
        round(.,3) %>% as.data.frame %>% t

    mod <- data.frame(model = deparse(substitute(model)) )
    ftable <- cbind( mod,measures)
    return(ftable)
}

FitTable <- rbind(fitable(OneFac), fitable(TwoFac)) %>% 
      rbind(fitable(TwoFacAlternative)) %>% 
      rbind(fitable(ThreeFac)) %>%
      rbind(fitable(FourFac)) %>%
      rbind(fitable(FiveFacMF)) %>%
      rbind(fitable(FiveFacAlternative))

colnames(FitTable) <- c('Model','Chi Squared','df','CFI','RMSEA','RMSEA Upper Bound','RMSEA Lower Bound')

kable_styling(kable(FitTable, caption='Fit Statistics'))
```

```{r MFSS Model Diagrams, fig.cap="Models", fig.asp = .3, echo=FALSE}
#Model Diagrams
layout(t(1:3))
semPaths(OneFac, "std", title = FALSE)
title("One Factor", line = 3)
semPaths(TwoFac, "std", title = FALSE)
title("C/F and A/L/P", line = 3)
semPaths(TwoFacAlternative, "std", title = FALSE)
title("EFA Suggested Two Factor", line = 3)
semPaths(ThreeFac, "std", title = FALSE)
title("C/F, A/L, and P", line = 3)
semPaths(FourFac, "std", title = FALSE)
title("C, F, A/L, and P", line = 3)
semPaths(FiveFacMF, "std", title = FALSE)
title("C, F, A, L, and P", line = 3)
semPaths(FiveFacAlternative, "std", title = FALSE)
title("EFA Suggested Five Factor", line = 3)

```


As can be seen from Table 2, although the chi-squared of the models tends to decrease as the factors increase and decreases noticeably in the last model--although this is surely connected to the correspondingly large decrease in degrees of freedom--none of the models is a good fit by the metric of RMSEA. In the first place, no model's 95% confidence interval for RMSEA is below 0.06, a recommended cutoff for an acceptable fit (Hu & Bentler 1999), and in the second place, the RMSEA confidence intervals for each of the models overlap every other model's, meaning that there is not a statistically significant difference between them in terms of RMSEA, at least by the 0.05 standard. The comparative fit index (CFI) indicates that the alternative five-factor model is superior to the rest, but once more, even this model does not achieve the recommended cutoff of 0.95 (Hu & Bentler 1999).

We can then say the following. The alternative five-factor model might be superior to the moral foundations five-factor model. If it is, the implication would be that 1) individual "moral foundations" are not as independent of one another as they theoretically seem to be, and clusters of moral beliefs and concerns composed of aspects of those foundations are in fact the true scales of an individual's morality and 2) those clusters of moral beliefs and concerns that seem to straddle theoretically distinct moral foundations might actually contain a hidden theoretical unity that could be uncovered after further reflection. An example of one possible theoretical unity is familial loyalty, which is theoretically distinguishable from loyalty to one's country or land. These two types of loyalty may not be as connected as their common name suggests. To speculate a bit, loyalty to one's family could be supposed on evolutionary grounds to be a "moral faculty" that developed prior to the "moral faculty" for loyalty to a group of unrelated humans. It would still, of course, be surprising if the latter "faculty" did not develop on the foundation of the former given the apparent similarity between the two loyalties as loyalties. Nevertheless, even this alternative five-factor model does not meet conventional standards of good fit on our data. Moreover, the fact that this model was devised using post hoc reasoning from EFA results makes the question of its prior probability, ie. its a priori plausibility, difficult to answer. For these two reasons, its validity should be taken with a grain of salt. Finally, the failure of the five-factor moral foundations model to attain conventional levels of CFI or RMSEA for goodness of fit raises a question about, but of course does not immediately invalidate, Graham et al.'s findings.

\newpage

## Testing Moral Foundations on Unfriendly Scales

As was stated above, the measuring morality survey contains 18 moral questionnaires other than the MFSS. By assembling items from these 18 questionnaires, I created a Frankenstein's monster of a moral foundations survey. For each moral foundation, I chose the four items from the 18 surveys that best represented it. I give examples below of the questions I selected to represent the foundations.

### Care

How immoral is it to ignore a woman struggling to carry bags of groceries?

### Fairness

How important is the value of being fair to others?

### Authority

How much do you agree with the statement "Obedience must be instilled in children"?

### Loyalty

How much do you agree with the statement "The USA should cooperate with other countries only when in its own interests"?

### Purity

How immoral is it to defecate, not wash one's hands, and then prepare dinner for oneself?

Since the questions come from different questionnaires with different response scales, I normalized the variables for each item. I do CFA with five models that correspond to the original five models tested above. I do not include the alternative models tested above that were developed from EFA. The reason for that is that EFA results indicate grouping of the items according to the particular questionnaire they are taken from. This issue plagues this series of tests, and as a result, these CFA results must also be taken with a grain of salt. However, comparison of the five-factor moral foundations model with the fewer factor models should still be useful for evaluating the plausibility of the moral foundations hypothesis. The CFA fit results, along with the model diagrams, are given in Table 4 and in the diagrams below.


```{r Exploratory for Invented Questionnaire, echo=FALSE}

#Creating Dataframe

RepData <- data.frame(
                  
                  #Care
                  
                  "C1" = data$DIT5, "C2" = data$MELS7, 
                  "C3" = data$MELS8, "C4" = -data$SV12,
                  
                  #Fairness
                  
                  "F1" = -data$SV3, "F2" = data$MELS3,
                  "F3" = data$EVA4, "F4" = data$EVA6,
                  
                  #Authority
                  
                  "A1" = data$L16, "A2" = -data$SV7, 
                  "A3" = -data$SV20, "A4" = data$EVA11,
                  
                  #Loyalty

                  "L1" = data$EVA2, "L2" = -data$I1, 
                  "L3" = -data$SV18,
                  
                  #Purity
                  
                  "P1" = -data$MR2, "P2" = data$MELS9, 
                  "P3" = data$MELS11, "P4" = data$EVA12
                  
                  )

RepData <- as.data.frame(scale(RepData))

#Scree Plot

eigen <- eigen(cor(RepData))

ap <- parallel(subject=nrow(RepData),var=ncol(RepData),
  rep=100,cent=.05)

nS <- nScree(x=eigen$values, aparallel=ap$eigen$qevpea)
#plotnScree(nS)

#Exploratory Factor Analysis

fit <- factanal(RepData, 3, rotation="promax")
#print(fit, digits=2, cutoff=.3, sort=FALSE)#

solution <- kaiser(fa(r = cor(RepData), nfactors = 4, rotate = "oblimin", fm = "mle"))
#solution

```


```{r Confirmatory for Invented Questionnaire, include = FALSE, echo=FALSE}

#Single Factor

RepModelOne <- 'All =~ C1+ C2 + C3 + C4 + F1+ F2 + F3 + F4 + A1+ A2 + A3 + A4 + L1+ L2 + L3 + P1+ P2 + P3 + P4' 
OneFac <- cfa(RepModelOne, data=RepData,std.lv=TRUE) 
#summary(OneFac,fit.measures=TRUE,standardized=TRUE)

#Two Factors

RepModelTwo <- 'Care.Fairness =~ C1+ C2 + C3 + C4 + F1+ F2 + F3 + F4
                Authority.Loyalty.Purity =~ A1+ A2 + A3 + A4 + L1+ L2 + L3 + P1+ P2 + P3 + P4' 
TwoFac <- cfa(RepModelTwo, data=RepData,std.lv=TRUE) 
#summary(TwoFac,fit.measures=TRUE,standardized=TRUE)

#Three Factors

RepModelThree <- 'Care.Fairness =~ C1+ C2 + C3 + C4 + F1+ F2 + F3 + F4
                  Authority.Loyalty =~ A1+ A2 + A3 + A4 + L1+ L2 + L3
                  Purity =~ P1+ P2 + P3 + P4' 
ThreeFac <- cfa(RepModelThree, data=RepData,std.lv=TRUE) 
#summary(ThreeFac,fit.measures=TRUE,standardized=TRUE)

#Three Factors 2

RepModelThreeCF <- 'Care =~ C1+ C2 + C3 + C4
                  Fairness =~ F1+ F2 + F3 + F4
                  Authority.Loyalty.Purity =~ A1+ A2 + A3 + A4 + L1+ L2 + L3 + P1+ P2 + P3 + P4' 
ThreeFacCF <- cfa(RepModelThreeCF, data=RepData,std.lv=TRUE) 
#summary(ThreeFac,fit.measures=TRUE,standardized=TRUE)

#Four Factors

RepModelFour <- 'Care =~ C1+ C2 + C3 + C4 
                  Fairness =~ F1+ F2 + F3 + F4
                  Authority.Loyalty =~ A1+ A2 + A3 + A4 + L1+ L2 + L3
                  Purity =~ P1+ P2 + P3 + P4' 
FourFac <- cfa(RepModelFour, data=RepData,std.lv=TRUE) 
#summary(FourFac,fit.measures=TRUE,standardized=TRUE)

#Five Factors

RepModelFive <- 'Care =~ C1+ C2 + C3 + C4
                 Fairness =~ F1+ F2 + F3 + F4
                 Authority =~ A1+ A2 + A3 + A4
                 Loyalty =~ L1+ L2 + L3
                 Purity =~ P1+ P2 + P3 + P4' 
FiveFac <- cfa(RepModelFive, data=RepData,std.lv=TRUE) 
#summary(FiveFac,fit.measures=TRUE,standardized=TRUE)


```


```{r Invented Questionnaire Models, fig.cap="Models", fig.asp = .3, echo=FALSE}
# Model Diagrams

layout(t(1:3))

semPaths(OneFac, "std", title = FALSE)
title("One Factor", line = 3)

semPaths(TwoFac, "std", title = FALSE)
title("C/F and A/L/P", line = 3)

semPaths(ThreeFac, "std", title = FALSE)
title("C/F, A/L and P", line = 3)

semPaths(ThreeFacCF, "std", title = FALSE)
title("C, F and A/L/P", line = 3)

semPaths(FourFac, "std", title = FALSE)
title("C, F, A/L, and P", line = 3)

semPaths(FiveFac, "std", title = FALSE)
title("C, F, A, L, and P", line = 3)

```

As was the case above, no model reaches conventional standards for good fit in the realm of either CFI or RMSEA. Unlike in the testing above, however, the three-factor model with care and fairness distinguished, the four-factor model, and the five-factor model are significantly better than the models with fewer factors or with care and fairness combined. This suggests that care and fairness have a decent claim to being separated as factors when factors are forced to correspond to moral foundations or groups of moral foundations. In the second place, since the five-factor model is statistically better, according to RMSEA, than the three-factor model with care and fairness distinguished, the group of loyalty, purity, and authority likely has divisions within it, as Graham et al. claim. Nevertheless, none of the models reach standard levels for goodness of fit, so the validity of a foundations-based factor model is questionable according to these results. 

With that being said, however, the weakness of these results could be an artifact of the phenomenon mentioned above, that items in this artificial survey were heavily correlated with items that were taken from the same questionnaire. The effect of this correlation on the correlation matrix of the artificial survey dataset, and not the weakness of moral foundations theory, could be the cause of the null results. For this reason, I will do one final round of testing using a non-constructed questionnaire from the measuring morality survey. Using a non-constructed questionnaire should avoid the pitfalls of the artificial questionnaire approach and, provided the non-constructed questionnaire has questions that clearly correspond to moral foundations, it should provide a good foreign testing ground for Graham et al.'s model.

```{r fit statistics for Invented Questionnaire, echo=FALSE}

#Fit Statistics

FitTable <- rbind(fitable(OneFac), fitable(TwoFac)) %>% 
      rbind(fitable(ThreeFac)) %>%
      rbind(fitable(ThreeFacCF)) %>%
      rbind(fitable(FourFac)) %>%
      rbind(fitable(FiveFac)) 

colnames(FitTable) <- c('Model','Chi Squared','df','CFI','RMSEA','RMSEA Upper Bound','RMSEA Lower Bound')

kable_styling(kable(FitTable, caption='Fit Statistics'))
```


\newpage

## The Moralization of Everyday Life Scale

The questionnaire I will use is the moralization of everyday life scale (MELS). The MELS, which has 12 items, was included in full in the measuring morality survey, and with the exceptions of two questions that *might* fit the purity foundation but seem to be too remote from normal morality to include, each of its questions corresponds more or less clearly to a moral foundation. The text of the survey is given below.

### MELS Text

Below you’ll be presented with a variety of situations and be asked to say whether certain behaviors in those situations would be morally wrong. Please use the following scale from 1 to 7, to indicate the degree to which you judge the behavior to be wrong (if at all).

1 = Not at all wrong; has nothing to do with morality. 
7 = Very wrong; an extremely immoral action

1. Lying about a test score when reporting performance to a teacher.
2. Faking an injury to collect on insurance.
3. Parking in a handicapped parking spot when not handicapped.
4. Using someone else’s toothbrush without his or her permission.
5. Packing for a trip at the last minute.
6. Choosing to wake up late, despite having a busy day ahead.
7. Ignoring a woman struggling to carry bags of groceries.
8. Ignoring a driver whose car is stuck in the snow.
9. An 18-year-old girl breaking an abstinence vow to have premarital sex.
10. Drinking 10 beers at a party and vomiting several times.
11. Defecating, not washing one’s hands, and then preparing dinner for oneself.
12. Wearing a pair of pants for three weeks without washing them.


Again, although questions 5 and 6 might plausibly be said to reflect the purity foundation of moral foundations theory, I judge them to be too much of a stretch, especially when compared to the questions Graham et al. use to estimate purity, and for that reason I will not include them. Questions 1, 2, and 3 clearly measure fairness (in each case, someone breaks a rule or lies in order to obtain an unfair advantage). Question 4 is somewhat ambiguous since it involves both illicit use of another's property and something (using another person's toothbrush) that many find to be disgusting. My judgment is that the latter factor is more important for most people (a small-n survey of my three roommates indicates that 100% of people feel this way), and for that reason, I will include it in the purity category. Questions 7 and 8 clearly correspond to the care foundation, and finally, questions 9 through 12 clearly correspond to the purity category. 

```{r Scree for MELS, fig.cap="MELS Scree Plot", fig.width=5, fig.height=4, fig.align = "center", echo=FALSE}

#Creating Dataframe

MELSData <- data.frame(
                  
                  #Care
                  
                  "C1" = data$MELS7, "C2" = data$MELS8, 
                  
                  #Fairness
                  
                  "F1" = data$MELS1, "F2" = data$MELS2,
                  "F3" = data$MELS3, 
                  
                  #Purity
                  
                  "P1" = data$MELS4, "P2" = data$MELS9, 
                  "P3" = data$MELS10, "P4" = data$MELS11
                  
                  )

#Scree Plot

eigen <- eigen(cor(MELSData))

ap <- parallel(subject=nrow(MELSData),var=ncol(MELSData),
  rep=100,cent=.05)

nS <- nScree(x=eigen$values, aparallel=ap$eigen$qevpea)
plotnScree(nS)

```

```{r EFA for MELS, echo=FALSE }
#Exploratory Factor Analysis

solution <- kaiser(fa(r = cor(MELSData), nfactors = 2, rotate = "oblimin", fm = "mle"))
kable_styling(kable(round(loadings(solution),2), caption='Two Factors'))

solution <- kaiser(fa(r = cor(MELSData), nfactors = 3, rotate = "oblimin", fm = "mle"))
kable_styling(kable(round(loadings(solution),2), caption='Three Factors'))

```

Thus the ten questions can be broken up into groups that correspond to three of the five moral foundations, care, fairness, and purity. The results of Graham et al.'s paper suggest that we should expect to find a three-factor model to fit these ten items much better than a one- or two-factor model. To add a bit of excitement, I also perform EFA to generate some ideas for alternative factor models. The relevant scree plot is presented as figure 4. Since the non-graphical indices are bivocal between using two and three factors, I perform EFA with both numbers. The results are listed in Tables 5 and 6.

In the two factor results, factor one has significant loadings on the care items and one of the purity items, and factor two has significant loadings on the fairness items and three of the purity items. Since I cannot discern a reason for the distinction between the purity items, I will not use the results of the two factor EFA to construct an alternative model. In the three-factor results, factor one has significant loadings on the care items, factor two has significant loadings on the purity items, and factor three has significant loadings on the fairness items. The three-factor EFA thus suggests the model Graham et al. would presumably support. For this reason, I will only conduct CFA on a one-factor model, a two-factor model split between care and fairness, on one hand, and purity, on the other, and a three-factor model that separates care, fairness, and purity. The results of the CFA can be seen in Table 7. Model diagrams for the three models can be seen in figure 3.

```{r CFA for MELS, echo=FALSE}

#Single Factor

MELSModelOne <- 'All =~ C1+ C2 + F1+ F2 + F3 + P1+ P2 + P3 + P4' 
OneFac <- cfa(MELSModelOne, data=MELSData,std.lv=TRUE) 
#summary(OneFac,fit.measures=TRUE,standardized=TRUE)

#Two Factors

MELSModelTwo <- 'Care.Fairness =~ C1+ C2 + F1+ F2 + F3 
                Purity =~ P1+ P2 + P3 + P4' 
TwoFac <- cfa(MELSModelTwo, data=MELSData,std.lv=TRUE) 
#summary(TwoFac,fit.measures=TRUE,standardized=TRUE)

#Three Factors

MELSModelThree <- 'Care =~ C1+ C2 
                  Fairness=~ F1 + F2 + F3
                  Purity =~ P1+ P2 + P3 + P4' 
ThreeFac <- cfa(MELSModelThree, data=MELSData,std.lv=TRUE) 
#summary(ThreeFac,fit.measures=TRUE,standardized=TRUE)

```


```{r MELS Models, fig.cap="Models", fig.asp = .3, echo=FALSE}
# Model Diagrams

layout(t(1:3))

semPaths(OneFac, "std", title = FALSE)
title("One Factor", line = 3)

semPaths(TwoFac, "std", title = FALSE)
title("C/F and Pr", line = 3)

semPaths(ThreeFac, "std", title = FALSE)
title("C, F, and P", line = 3)
```

```{r MELS Fit Statistic, echo=FALSE}
#Fit Statistics

layout(t(1:2))

FitTable <- rbind(fitable(OneFac), fitable(TwoFac)) %>% 
      rbind(fitable(ThreeFac))

colnames(FitTable) <- c('Model','Chi Squared','df','CFI','RMSEA','RMSEA Upper Bound','RMSEA Lower Bound')

kable_styling(kable(FitTable, caption='Fit Statistics'))
```

Although even the best model does not attain the standard qualifications for being a good fit, the three-factor model that accords with Graham et al.'s paper is significantly better than the one and two-factor models. This suggests that the care, fairness, and purity foundations are reasonably independent from one another. 

It remains the case, however, that the model suggested by Graham et al.'s paper was not a good fit by the conventional standards in any of the three tests. Judging by the relatively small communalities found in the EFA results for the first and last sets of data, the reason may be that the model, although it captures some of the structure of the correlation of moral items, oversimplifies the relationships between items found in different moral foundations groups. This might be remediable by choosing items with a higher degree of specificity. For example, the second loyalty item in the MFSS, "break off all communications with your immediate and extended family for a year," a priori appears to concern care as well as loyalty, unlike the other two loyalty items. On the other hand, moral foundations theory might be too naive in supposing that care as such can be separated from loyalty as such, for there is reason to believe that care and loyalty to one's family might be as closely related as loyalty to one's family and loyalty to one's country. The way forward here seems to be to a-theoretically gather moral questions from all walks of life and cultures and then, using theory, to make predictions about the groupings of those items. By using an extensive number of items, researches should be able to find subgroups of the moral foundations, or new foundations altogether, whose correlations could be examined in order to confirm or modify Graham et al.'s model. For example, if the survey contained enough items related to care, loyalty to family, and loyalty to country, and if those respective items had high factor loadings on three distinct factors, then the correlations between those three factors would indicate whether loyalty to family and loyalty to country belong together and justify the loyalty foundation or, on the contrary, loyalty to family and care are more closely related and the loyalty foundation is illusory.

\newpage

# Works Cited

Davie, C., Sibley, C., Liu, J. 2014. "Confirmatory Factor Analysis of the Moral Foundations." *Social Pychology*, 45, 431-446.

Graham, J. & Haidt, J. 2012. “Sacred Values and Evil Asversaries: A Moral Foundations Approach.” in *The Social Psychology of Morality: Exploring the Causes of Good and Evil*, edited by P. Shaver and M. Mikulincer. New York: APA Books

Graham, J., Nosek, B. A., Haidt, J., Iyer, R., Koleva, S., & Ditto, P. H. 2011. "Mapping the Moral Domain." *Journal of Personality and Social Psychology*, 101(2), 382–385

Hu, L. & Bentler, P. M. 1999. "Cutoff Criteria for Fit Indexes in Covariance Structure Analysis: Conventional Criteria versus New Alternatives." *Structural Equation Modeling*, 6(1), 1-55.

Lovett, B., Alexander J., & Wiltermuth, S. 2012. “Individual Differences in the Moralization of Everyday Life.” *Ethics and Behavior*.

Tamul, D, Elson, M., Ivory, J., Hotter, J., Lanier, M., Wolf, J., & Nadia I. Martínez-Carrillo. 2020. “Moral Foundations' Methodological Foundations: A Systematic Analysis of Reliability in Research Using the Moral Foundations Questionnaire.” *PsyArXiv*. doi:10.31234/osf.io/shcgv.

Yilmaz, O., et al. 2016 “Validation of the Moral Foundations Questionnaire in Turkey and Its Relation to Cultural Schemas of Individualism and Collectivism.” *Personality and Individual Differences*, 99, 149–154.

\newpage

# Mathematical Appendix

## The Factor Model

We assume that we have n observations on p variables. Our data matrix $Y$ will then have the following form:

$$
\begin{bmatrix} 
y_{11} & y_{12} & \ldots & y_{1p} \\
y_{21} & y_{22} & \ldots & y_{2p}\\
\ldots & \ldots & \ldots & \ldots\\
y_{n1} & y_{n2} & \ldots & y_{np}
\end{bmatrix}
$$
where each row vector, $\boldsymbol{y_{i}}$, is one of our observations. Our factor model will then be, for any $\boldsymbol{y_{i}}$, the following:

$$y_{1}*=\lambda_{11}f_{1} + \lambda_{12}f_{2} + \ldots + \lambda_{1m}f_{m} +\epsilon_{1}$$
$$y_{2}*=\lambda_{21}f_{1} + \lambda_{22}f_{2} + \ldots + \lambda_{2m}f_{m} +\epsilon_{2}$$
$$\ldots$$
$$y_{p}*=\lambda_{p1}f_{1} + \lambda_{p2}f_{2} + \ldots + \lambda_{pm}f_{m} +\epsilon_{p}$$

where $y*$ is the demeaned value of $y$. We call the $\lambda$'s the factor loadings, and we call the $f$'s the factors. We allow each observation, $\boldsymbol{y}$ to have its own particular factor values, but we restrict the factor loadings so that they are the same for all observations. Each individual equation above thus expresses each variable as a linear combination of factors, which can be thought of as latent variables. The primary goal of factor analysis is to estimate the values of the loadings so as to understand the effects of each factor on each of the variables.

We can write the series of equations above more succinctly in matrix notation if we define $\Lambda$ to be

$$
\begin{bmatrix} 
\lambda_{11} & \lambda_{12} & \ldots & \lambda_{1p} \\
\lambda_{21} & \lambda_{22} & \ldots & \lambda_{2p}\\
\ldots & \ldots & \ldots & \ldots\\
\lambda_{n1} & \lambda_{n2} & \ldots & \lambda_{np}
\end{bmatrix}
.$$

$\boldsymbol{y*}$ to be the demeaned observation (column) vector, $\boldsymbol{f}$ to be the column vector composed of the factors, and $\boldsymbol{\epsilon}$ to be the column vector of the error terms:

$$\boldsymbol{y*}=\Lambda \boldsymbol{f}+\boldsymbol{\epsilon}$$

## Estimation of the Loadings

We will limit our discussion of estimation here to the principle component method of estimating factor loadings. To begin, we need to enumerate the assumptions that make estimation possible:

$$E(\boldsymbol{f})=\boldsymbol{0},$$
$$cov(\boldsymbol{f})=I,$$
$$E(\boldsymbol{\epsilon})=\boldsymbol{0},$$
$$cov(\boldsymbol{\epsilon})=\Psi,$$
$$
=
\begin{bmatrix} 
\psi_{1} & 0 & \ldots & 0 \\
0 & \psi_{2} & \ldots & 0\\
\ldots & \ldots & \ldots & \ldots\\
0 & 0 & \ldots & \psi_{p}
\end{bmatrix}
,$$ and, finally,

$$cov(\boldsymbol{f},\boldsymbol{\epsilon})=\boldsymbol{0}.$$

Since our model defines $\boldsymbol{y*}$ in terms of our factors, loadings, and error terms, and since demeaning our data does not change its variances and covariances, we can define the covariance matrix of our sample in terms of those same factors, loadings, and errors:

$$\Sigma=cov(\Lambda \boldsymbol{f}+\boldsymbol{\epsilon})$$
Since we have assumed that $\boldsymbol{f}$ and $\boldsymbol{\epsilon}$ are not correlated,

$$cov(\Lambda \boldsymbol{f}+\boldsymbol{\epsilon})=cov(\Lambda \boldsymbol{f}) + cov(\boldsymbol{\epsilon}).$$

Since $\Lambda$ is not a variable, and since we have assumed that $cov(\boldsymbol{\epsilon})=\Psi,$

$$cov(\Lambda \boldsymbol{f}) + cov(\boldsymbol{\epsilon})=\Lambda cov(\boldsymbol{f})\Lambda'+\Psi.$$

Finally, since $cov(\boldsymbol{f})=I$ by assumption, 

$$\Lambda cov(\boldsymbol{f})\Lambda'+\Psi = \Lambda\Lambda'+\Psi = \Sigma.$$

Factor analysis thus aims to reproduce the covariance of the observed variables with fewer free dimensions. 

Since we are working with a sample of the population, we have access only to the sample covariance matrix, $S$. We want, then, to estimate our $\Lambda$ matrix (and $\Psi$) by solving 

$$S=\hat{\Lambda}\hat{\Lambda'}+\hat{\Psi}$$

Following the principle component method, we initially ignore $\hat{\Psi}$ and, as a result, are left with the relatively easy problem of finding a pxm matrix $\hat{\Lambda}$ such that $S=\hat{\Lambda}\hat{\Lambda'}$. As we will see, this does not mean that we are discarding $\hat{\Psi}$ and consequently fitting a model with no error--$\hat{\Psi}$ will return.

Since $S$ is equal to $Y*'Y*$,where $Y*$ is the demeaned sample matrix and assumed to be of full column rank, $S$ is positive definite, and since $S$ is positive definite, we can decompose it into a product of its modal matrix and its eigenvalue matrix. That is, if $M$ is the modal matrix of $S$, and if $L$ is the matrix whose diagonal elements are the eigenvalues of the column vectors of$M$ with respect to $S$, then 

$$SM=ML$$

$$SMM'=MLM'$$, and because modal matrices are orthogonal matrices,

$$S=MLM'$$
$$=ML^{\frac{1}{2}}L^{\frac{1}{2}}M'$$
$$=(ML^{\frac{1}{2}})(ML^{\frac{1}{2}})'$$
Tempting as it may be to identify $\hat{\Lambda}$ with $ML^{\frac{1}{2}}$, we cannot yet do so since $ML^{\frac{1}{2}}$ is a $p \times p$ matrix whereas $\hat{\Lambda}$ is, by assumption, a $p \times m$ matrix with $m < p$. Were we to identify $\hat{\Lambda}$ with $ML^{\frac{1}{2}}$, we would both lose the power of the factor model, which is to reduce the effective dimensionality of the covariance of our sample, and be ignoring our model's error terms. Hence we instead define $\hat{\Lambda}$ to be $M^{*}L^{*\frac{1}{2}}$, where $L^{*}$ is the $m \times m$ matrix formed by removing the right $p-m$ columns and the bottom $p-m$ rows of the $L$ matrix, and hence has as its diagonals the $m$ greatest eigenvalues, and $M^{*}$ is the $p \times m$ matrix formed by removing the right $p-m$ columns of $M$ and hence is composed of the $m$ eigenvectors of $S$ with the largest eigenvalues. Now that we have $\hat{\Lambda}$, we can estimate $\Psi$ as

$$\hat{\Psi}=S-\hat{\Lambda}\hat{\Lambda}'$$ since, as we saw earlier,

$$S=\hat{\Lambda}\hat{\Lambda'}+\hat{\Psi}.$$

## Rotation

Let $T$ be an orthogonal matrix. Since $TT'=I$,

$$\boldsymbol{y*}=\Lambda TT' \boldsymbol{f}+\boldsymbol{\epsilon},$$
$$=\Lambda_{*} \boldsymbol{f_{*}}+\boldsymbol{\epsilon},$$ where $\Lambda_{*}=\Lambda T,$ and $f_{*}=T'\boldsymbol{f}.$ Similarly, 

$$S=\Lambda_{*}\Lambda_{*}' +\Psi$$ since

$$\Lambda_{*}\Lambda_{*}'=\Lambda TT'\Lambda'=\Lambda I \Lambda'=\Lambda \Lambda'.$$

We can take advantage of this property of the factor model to rotate our loadings so as to aid in interpreting our factors. We interpret our factors by observing which variables they have high loadings on and which variables they have low loadings on. If a factor has high loadings on three variables that measure, say, vocabulary, reading comprehension, and analogical reasoning, and another factor has high loadings on three variables that measure running speed, jumping distance, and maximal squat weight, then we would interpret the first factor to be a latent verbal ability variable and the second to be a latent lower body fitness variable. Rotating our factor loadings so as to concentrate the loadings of one factor on certain variables, the loadings of another factor on certain other variables, etc. allows us to interpret the representational significance of the factors.

Oblique rotations are non-orthogonal transformations of the factors with a matrix $T$ such that $TT' \ne I.$ The covariance matrix of $f*$ will now not be equal to $I$ since $$cov(Tf)=Tcov(f)T'=TT'\ne I$$
Hence factors will be correlated after an oblique transformation is applied. For factors that are not truly orthogonal but have small enough correlations to potentially be representing separate latent variables, oblique transformations can be used to consolidate loadings and ease interpretation. 




